# ğŸš€ Fine-Tuning de ModÃ¨les Multimodaux sur DonnÃ©es Textuelles
Ce dÃ©pÃ´t fournit les ressources et le code pour affiner des modÃ¨les multimodaux uniquement 
avec des donnÃ©es textuelles. L'objectif est de spÃ©cialiser la partie langage sans altÃ©rer 
les capacitÃ©s de traitement d'images du modÃ¨le. <br/>

# ğŸ“Œ Contexte
Les modÃ¨les multimodaux, capables d'analyser Ã  la fois du texte et des images, sont de plus en plus 
utilisÃ©s. Cependant, dans certains cas d'usage, il est nÃ©cessaire d'amÃ©liorer uniquement leur capacitÃ© 
de traitement du texte sans affecter leur compÃ©tence sur les images. Ce projet vise donc Ã  affiner 
la partie textuelle de modÃ¨les multimodaux, en utilisant des techniques d'entraÃ®nement avancÃ©es 
telles que PEFT et QLoRA. <br/>

# ğŸ— ModÃ¨les Ã©tudiÃ©s
Nous avons travaillÃ© sur trois modÃ¨les multimodaux : <br/>

- Llava-1.6-Vicuna-13B <br/>
Checkpoint : llava-hf/llava-v1.6-vicuna-13b-hf <br/>
Fine-tuning avec PEFT et bitsandbytes <br/>
- Pixtral-12B <br/>
Checkpoint : unsloth/Pixtral-12B-2409 <br/>
Fine-tuning avec Unsloth <br/>
- Llama-3.2-11B-Vision <br/>
Checkpoint : unsloth/Llama-3.2-11B-Vision-Instruct <br/>
Fine-tuning avec Unsloth <br/>

# ğŸ”š Conclusion
Ce projet dÃ©montre la faisabilitÃ© dâ€™un fine-tuning ciblÃ© sur la partie textuelle des modÃ¨les multimodaux. 
En utilisant des techniques avancÃ©es d'entraÃ®nement, nous avons rÃ©ussi Ã  amÃ©liorer la comprÃ©hension 
et la gÃ©nÃ©ration de texte tout en conservant lâ€™intÃ©gritÃ© des autres fonctionnalitÃ©s du modÃ¨le. <br/>
Les notebooks disponibles dans ce dÃ©pÃ´t dÃ©taillent le processus d'entraÃ®nement pour chaque modÃ¨le, 
permettant une reproduction et une adaptation faciles Ã  d'autres cas d'utilisation. <br/>

# ğŸ“œ Licence
Ce projet est disponible sous la licence MIT.
